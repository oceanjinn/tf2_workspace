{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n",
      "<TensorSliceDataset shapes: ((28, 28), (10,)), types: (tf.float32, tf.float32)>\n",
      "<BatchDataset shapes: ((None, 28, 28), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, datasets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# 数据读取和预处理\n",
    "# 1. 读取训练集、测试集数据\n",
    "# 2. 对数据进行预处理。X数据（像素灰度）进行归一化处理，一般处理到[0, 1]或[-1, 1]之间\n",
    "#    对Y数据（分类标签）进行one-hot编码，去掉数字标签可能带来的大小关系\n",
    "# 3. 使用tf.data.Dataset.from_tensor_slice((x, y)) 将三维的图片数据，按照第一个维度进行展开，及进行“打平”操作\n",
    "# 4. 使用tf.data.Dataset.from_tensor_slice.batch 方法，设置批处理数据的大小\n",
    "(x, y), (x_val, y_val) = tf.keras.datasets.mnist.load_data() #  如果没有from ... import ... 语句，需要一层层引用\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)/255. # 转换数据范围到[0,1]\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y = tf.one_hot(y, depth=10) # one-hot 编码，去掉标签的大小关系\n",
    "print(x.shape, y.shape)\n",
    "# tf.data.Dataset.from_tensor_slices真正作用是切分传入Tensor的第一个维度，生成相应的dataset，即第一维表明数据集中数据的数量，之后切分batch等操作都以第一维为基础。\n",
    "# 打平后的数据维度为((28, 28)图片, (10, )标记)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y)) \n",
    "print(train_dataset)\n",
    "train_dataset = train_dataset.batch(600) # 暂：转换完的维度(None, 28, 28)中None\n",
    "#train_dataset = train_dataset.repeat(20) # 如果用for epoch in range(20)，则不用这一句，效果一样\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 28, 28), (None, 10)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "# 网络搭建\n",
    "# 1. 使用Sequential容器，搭建3曾网络如下\n",
    "# 2. 需要乡下一层传递时，需使用activation函数\n",
    "# 3. 输出层因不用向下一层传递，因此不用激活函数activation\n",
    "model = keras.Sequential([ # 三个非线性层的嵌套模型，包括两个隐藏层，一个输出层\n",
    "        layers.Dense(256, activation='relu'), # 隐藏层1，用relu作为激活函数\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(10)]) # 输出层不用激活函数，输出节点数为10\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optimizers.SGD(learning_rate=0.1) \n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 1.8820798\n",
      "0 20 loss: 0.6128091\n",
      "0 40 loss: 0.44580832\n",
      "0 60 loss: 0.41272196\n",
      "0 80 loss: 0.30545777\n",
      "1 0 loss: 0.29905117\n",
      "1 20 loss: 0.3122517\n",
      "1 40 loss: 0.26045063\n",
      "1 60 loss: 0.25969476\n",
      "1 80 loss: 0.21582326\n",
      "2 0 loss: 0.20495807\n",
      "2 20 loss: 0.2327683\n",
      "2 40 loss: 0.21076581\n",
      "2 60 loss: 0.21348256\n",
      "2 80 loss: 0.18165094\n",
      "3 0 loss: 0.17308609\n",
      "3 20 loss: 0.19999586\n",
      "3 40 loss: 0.18444395\n",
      "3 60 loss: 0.18904938\n",
      "3 80 loss: 0.16246955\n",
      "4 0 loss: 0.1547785\n",
      "4 20 loss: 0.18063948\n",
      "4 40 loss: 0.16685429\n",
      "4 60 loss: 0.17246328\n",
      "4 80 loss: 0.14926074\n",
      "5 0 loss: 0.14172319\n",
      "5 20 loss: 0.16635369\n",
      "5 40 loss: 0.15403236\n",
      "5 60 loss: 0.16019313\n",
      "5 80 loss: 0.13918146\n",
      "6 0 loss: 0.1321174\n",
      "6 20 loss: 0.15535897\n",
      "6 40 loss: 0.14401066\n",
      "6 60 loss: 0.15048075\n",
      "6 80 loss: 0.13082191\n",
      "7 0 loss: 0.12446917\n",
      "7 20 loss: 0.14652878\n",
      "7 40 loss: 0.13570285\n",
      "7 60 loss: 0.14250867\n",
      "7 80 loss: 0.1239799\n",
      "8 0 loss: 0.11822276\n",
      "8 20 loss: 0.13899048\n",
      "8 40 loss: 0.12857303\n",
      "8 60 loss: 0.1356633\n",
      "8 80 loss: 0.11819247\n",
      "9 0 loss: 0.11285395\n",
      "9 20 loss: 0.1325012\n",
      "9 40 loss: 0.12237534\n",
      "9 60 loss: 0.12957875\n",
      "9 80 loss: 0.11303778\n",
      "10 0 loss: 0.10835387\n",
      "10 20 loss: 0.12661913\n",
      "10 40 loss: 0.11707962\n",
      "10 60 loss: 0.124341816\n",
      "10 80 loss: 0.10852002\n",
      "11 0 loss: 0.10435986\n",
      "11 20 loss: 0.12131219\n",
      "11 40 loss: 0.112407275\n",
      "11 60 loss: 0.119673535\n",
      "11 80 loss: 0.10448323\n",
      "12 0 loss: 0.100730106\n",
      "12 20 loss: 0.11661448\n",
      "12 40 loss: 0.108272575\n",
      "12 60 loss: 0.115415245\n",
      "12 80 loss: 0.100881726\n",
      "13 0 loss: 0.0975855\n",
      "13 20 loss: 0.11251363\n",
      "13 40 loss: 0.10457549\n",
      "13 60 loss: 0.111588605\n",
      "13 80 loss: 0.097642444\n",
      "14 0 loss: 0.09472331\n",
      "14 20 loss: 0.1086705\n",
      "14 40 loss: 0.10116512\n",
      "14 60 loss: 0.10804644\n",
      "14 80 loss: 0.09467352\n",
      "15 0 loss: 0.09208553\n",
      "15 20 loss: 0.10509541\n",
      "15 40 loss: 0.09806077\n",
      "15 60 loss: 0.10479476\n",
      "15 80 loss: 0.09186776\n",
      "16 0 loss: 0.08966462\n",
      "16 20 loss: 0.101841286\n",
      "16 40 loss: 0.0951381\n",
      "16 60 loss: 0.10180095\n",
      "16 80 loss: 0.08932173\n",
      "17 0 loss: 0.08739651\n",
      "17 20 loss: 0.09883137\n",
      "17 40 loss: 0.0924884\n",
      "17 60 loss: 0.09906203\n",
      "17 80 loss: 0.08696682\n",
      "18 0 loss: 0.085330814\n",
      "18 20 loss: 0.095953\n",
      "18 40 loss: 0.08999161\n",
      "18 60 loss: 0.09654948\n",
      "18 80 loss: 0.08484326\n",
      "19 0 loss: 0.08342217\n",
      "19 20 loss: 0.09332642\n",
      "19 40 loss: 0.08762514\n",
      "19 60 loss: 0.094306014\n",
      "19 80 loss: 0.08286127\n",
      "20 0 loss: 0.081605524\n",
      "20 20 loss: 0.090814784\n",
      "20 40 loss: 0.08543321\n",
      "20 60 loss: 0.09220876\n",
      "20 80 loss: 0.08102488\n",
      "21 0 loss: 0.07980624\n",
      "21 20 loss: 0.08840984\n",
      "21 40 loss: 0.08335055\n",
      "21 60 loss: 0.09020052\n",
      "21 80 loss: 0.07928512\n",
      "22 0 loss: 0.078175776\n",
      "22 20 loss: 0.08615553\n",
      "22 40 loss: 0.08141755\n",
      "22 60 loss: 0.08829459\n",
      "22 80 loss: 0.07756946\n",
      "23 0 loss: 0.07663217\n",
      "23 20 loss: 0.084011346\n",
      "23 40 loss: 0.07959974\n",
      "23 60 loss: 0.08650621\n",
      "23 80 loss: 0.07603019\n",
      "24 0 loss: 0.075235754\n",
      "24 20 loss: 0.08194164\n",
      "24 40 loss: 0.077885285\n",
      "24 60 loss: 0.08479723\n",
      "24 80 loss: 0.07448369\n",
      "25 0 loss: 0.07392822\n",
      "25 20 loss: 0.08002771\n",
      "25 40 loss: 0.076221325\n",
      "25 60 loss: 0.08314586\n",
      "25 80 loss: 0.07298897\n",
      "26 0 loss: 0.07264376\n",
      "26 20 loss: 0.07812594\n",
      "26 40 loss: 0.07459537\n",
      "26 60 loss: 0.08159794\n",
      "26 80 loss: 0.0715713\n",
      "27 0 loss: 0.07143732\n",
      "27 20 loss: 0.076303065\n",
      "27 40 loss: 0.07305942\n",
      "27 60 loss: 0.080093086\n",
      "27 80 loss: 0.070218064\n",
      "28 0 loss: 0.07025144\n",
      "28 20 loss: 0.07456549\n",
      "28 40 loss: 0.07157107\n",
      "28 60 loss: 0.07868011\n",
      "28 80 loss: 0.06899309\n",
      "29 0 loss: 0.06914288\n",
      "29 20 loss: 0.07288002\n",
      "29 40 loss: 0.07014755\n",
      "29 60 loss: 0.07733906\n",
      "29 80 loss: 0.06782764\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "\n",
    "losses = []\n",
    "# ''' 用epoch和for循环实现迭代训练\n",
    "for epoch in range(30):\n",
    "    # 第四步： 循环迭代优化\n",
    "    for step, (x, y) in enumerate(train_dataset): # python 语法，enumerate()方法将train_dataset中的后两维数据以枚举形式付给step对应的(x, y)变量\n",
    "        with tf.GradientTape() as tape: # python 语法，对于后续需要释放的资源，使用with...as...语句，避免忘记释放资源\n",
    "            # ？？？\n",
    "            x = tf.reshape(x, (-1, 28*28)) # 打平操作\n",
    "            out = model(x) # 第一步：得到模型输出, 相当于表达式中的Y\n",
    "            # 第二步：计算平均误差\n",
    "            loss = tf.square(out - y) # 计算平方和[b, 10]\n",
    "            loss = tf.reduce_sum(loss) / x.shape[0] # 计算每个样本的平均误差[b]\n",
    "            # 第三步：计算并优化参数[w1, w2, w3, b1, b2, b3]\n",
    "            grads = tape.gradient(loss, model.trainable_variables) # 自动计算梯度\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables)) # w'=w-lr*grad, 更新网络参数\n",
    "        # 每500次计算绘制一次图像\n",
    "        if step % 20 == 0: \n",
    "            print(epoch, step, 'loss:', loss.numpy())\n",
    "        # print(epoch, step, 'loss:', loss.numpy()) # step = 数据第一维度数量（图片张数）/ n； 最大值为 batch(n) 中的n\n",
    "    losses.append(float(loss))\n",
    "# '''\n",
    "\n",
    "# 储存模型\n",
    "model.save('mnist_model.h5')\n",
    "# 储存权重\n",
    "model.save_weights('mnist_model_weight.h5')\n",
    "# 储存checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  5130      \n",
      "=================================================================\n",
      "Total params: 337,674\n",
      "Trainable params: 337,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.1,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印model中的各个参数\n",
    "model.summary()  # 打印模型信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03869753, -0.00843564, -0.03202304, ..., -0.02361105,\n",
       "         -0.03781034,  0.04538522],\n",
       "        [ 0.02173847, -0.05168454,  0.02655206, ...,  0.05159335,\n",
       "         -0.03136662,  0.01947975],\n",
       "        [-0.04007988, -0.06495117, -0.05982079, ...,  0.04057609,\n",
       "         -0.01051266,  0.0242835 ],\n",
       "        ...,\n",
       "        [-0.06600653,  0.03256996,  0.05081888, ...,  0.06586224,\n",
       "         -0.00046503,  0.03464179],\n",
       "        [-0.06100262,  0.00493716, -0.07507886, ..., -0.04582621,\n",
       "         -0.04807085, -0.00524362],\n",
       "        [-0.01904261, -0.01534906, -0.01969153, ..., -0.00740599,\n",
       "          0.07291673, -0.0192333 ]], dtype=float32),\n",
       " array([-2.27938732e-03,  9.20504481e-02,  5.02940826e-02, -2.56354082e-02,\n",
       "         3.59268822e-02,  6.73896074e-02,  5.18304529e-03,  3.67791653e-02,\n",
       "        -8.28697160e-03,  7.80597255e-02, -1.77499112e-02,  1.93625670e-02,\n",
       "         6.45609386e-03,  2.84080133e-02, -5.90319373e-03,  1.14830494e-01,\n",
       "        -3.76271866e-02, -1.05293654e-02,  6.61319867e-02,  4.52375151e-02,\n",
       "         1.66929904e-02,  2.60886885e-02,  3.19450945e-02, -2.62790546e-02,\n",
       "         4.39378619e-02,  7.02270120e-02, -1.31711047e-02, -3.71001055e-03,\n",
       "         3.91337685e-02,  6.01891503e-02, -3.24724019e-02,  1.19354248e-01,\n",
       "         4.42231027e-03,  2.32045520e-02,  3.12074479e-02, -1.52142402e-02,\n",
       "         1.16276015e-02, -2.35467590e-02, -7.17603034e-05, -1.26320282e-02,\n",
       "         2.87485332e-03,  3.85552794e-02,  1.18410459e-03, -2.95333490e-02,\n",
       "        -5.59459999e-02, -4.28828551e-03,  6.44329097e-03, -4.11891267e-02,\n",
       "         5.28887194e-03,  1.04520749e-02, -3.05265114e-02,  1.86382513e-02,\n",
       "        -1.95069276e-02,  4.29730825e-02, -6.14308007e-02, -8.67611635e-03,\n",
       "        -1.67865139e-02,  2.11570337e-02,  8.75429809e-02,  5.36879189e-02,\n",
       "        -3.47332619e-02,  2.33607944e-02,  1.62856781e-03,  4.99040540e-03,\n",
       "         4.25510146e-02,  5.55522693e-03,  1.26744006e-02,  6.03185920e-03,\n",
       "        -7.75512457e-02, -2.38285139e-02,  2.66735088e-02, -2.79121976e-02,\n",
       "         3.74377668e-02, -3.78777348e-02, -9.04846042e-02,  1.23057505e-02,\n",
       "         2.07915697e-02, -1.55981854e-02,  3.66611294e-02,  4.90163546e-03,\n",
       "         4.24695760e-02, -2.54132021e-02, -4.36169608e-03, -1.72446407e-02,\n",
       "        -4.24639927e-03,  1.77336801e-02, -2.69002430e-02,  1.93054359e-02,\n",
       "        -7.64221326e-03, -3.92794684e-02, -7.04322709e-04, -1.34298783e-02,\n",
       "         4.64120544e-02, -2.56716390e-03, -1.25025231e-02, -1.56115163e-02,\n",
       "         5.26421256e-02,  2.90580746e-02,  6.07572347e-02, -9.25171003e-03,\n",
       "         6.63530305e-02,  2.38981657e-02,  5.28978631e-02,  3.78821082e-02,\n",
       "        -2.35741679e-02,  8.89319330e-02, -1.97301432e-02,  2.00705789e-02,\n",
       "        -2.32136603e-02,  1.47622181e-02,  4.39038267e-03, -1.14811910e-02,\n",
       "        -1.17882285e-02,  7.87563901e-03, -8.42123386e-03, -2.07769107e-02,\n",
       "        -4.65319231e-02,  5.26643358e-02,  4.33729775e-02,  5.38087264e-02,\n",
       "        -2.94097736e-02, -3.40087377e-02, -2.35557482e-02, -6.26590028e-02,\n",
       "        -2.60274671e-02,  4.96648028e-02,  8.08807313e-02, -6.95804274e-03,\n",
       "         1.71375256e-02, -2.24615838e-02,  4.89055626e-02,  6.42438754e-02,\n",
       "        -8.51223618e-03,  3.61480191e-02,  8.06020722e-02,  3.42250504e-02,\n",
       "         1.26641259e-01, -2.09875917e-03, -5.06697297e-02,  1.50579028e-02,\n",
       "        -3.56378295e-02, -1.73961297e-02,  5.99402934e-02,  1.99119076e-02,\n",
       "         8.37778323e-04, -1.09339319e-02,  1.54140610e-02,  2.37979065e-03,\n",
       "         7.91603923e-02,  5.85986227e-02, -9.57570225e-03, -3.64479306e-03,\n",
       "         2.39661746e-02,  3.03649344e-02, -1.20247947e-04,  4.82245497e-02,\n",
       "         3.03967595e-02,  1.53006790e-02,  5.54092927e-03,  1.70224845e-01,\n",
       "         3.29300910e-02, -6.79867482e-03, -8.85029417e-03, -1.36410324e-02,\n",
       "        -4.26375829e-02, -4.22370769e-02, -1.56992469e-02,  4.05965857e-02,\n",
       "         1.11925565e-02, -8.31184629e-03,  1.53100835e-02,  2.33452320e-02,\n",
       "        -9.97025520e-03,  7.61707649e-02, -3.63162868e-02,  4.50137034e-02,\n",
       "        -3.53533886e-02, -6.12724647e-02, -3.98955494e-02,  1.05594937e-02,\n",
       "         8.31705146e-03,  6.39412180e-03,  1.66365616e-02, -3.25039355e-03,\n",
       "        -2.10973043e-02,  8.49304348e-02,  3.94938067e-02, -2.82893162e-02,\n",
       "         3.29979393e-03, -1.96008272e-02, -1.53806303e-02, -3.72379273e-02,\n",
       "        -1.27220256e-02, -4.63995896e-02,  8.67747888e-02,  9.54101309e-02,\n",
       "        -9.28606465e-03, -6.15195883e-03, -4.63846780e-04, -1.18486090e-02,\n",
       "         1.05409231e-03, -2.59411875e-02,  2.41467729e-02, -8.58299318e-04,\n",
       "         8.19136798e-02, -3.32241096e-02, -6.50853384e-03, -5.42184850e-03,\n",
       "         1.83723681e-02,  2.07947090e-01,  2.02603894e-03, -3.40098329e-02,\n",
       "        -1.94145944e-02, -2.48213531e-03,  7.43892491e-02, -8.53805989e-03,\n",
       "        -6.27582613e-03,  2.41030846e-03, -5.32214157e-02,  5.94714731e-02,\n",
       "         4.15507853e-02,  8.32981318e-02,  6.07397873e-03, -6.03335211e-03,\n",
       "         3.79859842e-03, -4.78342967e-03,  1.44227371e-02,  1.64966565e-02,\n",
       "        -1.63802523e-02, -4.71369736e-03,  1.04508311e-01,  1.11256972e-01,\n",
       "        -1.98000092e-02, -4.64660972e-02, -2.95391958e-03, -2.19913982e-02,\n",
       "        -2.41189804e-02, -2.77546886e-02,  5.22587672e-02,  2.75132712e-03,\n",
       "         6.31616963e-03, -1.84989069e-02,  9.43168718e-03, -4.76834252e-02,\n",
       "        -1.52356969e-03, -7.30829779e-03, -2.63377205e-02, -5.63697331e-03,\n",
       "         4.84696738e-02, -3.62470858e-02, -1.48878256e-02, -6.19500428e-02,\n",
       "        -2.67514195e-02,  3.28527018e-03, -3.05437855e-02, -2.23562568e-02],\n",
       "       dtype=float32),\n",
       " array([[ 0.06437097, -0.07027819, -0.04252565, ...,  0.00984734,\n",
       "          0.00373465, -0.03988725],\n",
       "        [-0.07400545, -0.01196183,  0.01428749, ..., -0.06354596,\n",
       "         -0.07175618, -0.018051  ],\n",
       "        [-0.05177154,  0.04841359,  0.02840574, ..., -0.03361132,\n",
       "          0.04076095,  0.052472  ],\n",
       "        ...,\n",
       "        [-0.04926847, -0.00612837,  0.00396003, ..., -0.01784555,\n",
       "          0.00895003,  0.06213685],\n",
       "        [ 0.02495777, -0.05258614,  0.0056606 , ..., -0.07112773,\n",
       "         -0.08108117,  0.04648761],\n",
       "        [-0.03866657, -0.07164968,  0.0650349 , ...,  0.08270172,\n",
       "         -0.03018518, -0.0764274 ]], dtype=float32),\n",
       " array([-4.64397371e-02, -1.15090888e-02,  6.41209632e-03, -2.08940674e-02,\n",
       "        -7.48357968e-03,  3.42546888e-02,  2.44643670e-02, -2.27123648e-02,\n",
       "         1.93068609e-02, -7.37241516e-03, -4.48373370e-02, -2.59135719e-02,\n",
       "        -1.07831312e-02,  4.25686128e-02,  2.72341091e-02, -3.76213565e-02,\n",
       "        -7.27492198e-02,  8.65650624e-02, -1.81802958e-02,  1.41599840e-02,\n",
       "        -2.38149129e-02,  3.32790264e-03, -9.69924498e-03,  8.07783306e-02,\n",
       "         1.18286395e-02, -3.73511203e-03,  4.95404787e-02,  2.33505238e-02,\n",
       "        -2.73507610e-02,  2.93582794e-03, -2.60053505e-03,  3.56327109e-02,\n",
       "         6.62958473e-02, -2.60593239e-02,  1.07946442e-02,  4.95220013e-02,\n",
       "        -4.66315039e-02,  1.15844771e-01,  1.31810633e-02,  4.74516936e-02,\n",
       "        -3.30860801e-02, -1.57058202e-02, -1.93757769e-02,  1.15988560e-01,\n",
       "         3.32378410e-02, -3.18095181e-03,  2.35642400e-02,  4.19807769e-02,\n",
       "        -3.71421985e-02,  8.39043483e-02,  3.62211950e-02, -1.64784044e-02,\n",
       "        -2.08176934e-04, -1.89627167e-02, -3.89188193e-02,  5.38855605e-03,\n",
       "         7.64355808e-02, -1.32658584e-02, -3.07383928e-02, -1.21258479e-03,\n",
       "         7.13556185e-02,  9.35866833e-02,  2.01998204e-02,  8.42742324e-02,\n",
       "        -2.84582078e-02, -3.28163393e-02,  2.86803339e-02, -9.58094839e-03,\n",
       "         1.08897630e-02, -2.57326453e-03, -3.35362740e-02,  3.55485529e-02,\n",
       "         6.18910342e-02, -6.68006241e-02,  8.01573857e-04, -1.05807101e-02,\n",
       "         2.05716724e-03, -2.76392588e-04,  5.42606600e-02,  3.67957801e-02,\n",
       "        -4.57057841e-02,  2.72843204e-02,  2.60580215e-04,  3.53828296e-02,\n",
       "        -3.86679508e-02, -3.61751020e-02, -4.50104140e-02,  9.17005539e-03,\n",
       "        -7.48344660e-02,  1.10782236e-02,  1.64217595e-02, -4.21142951e-02,\n",
       "        -8.25434700e-02,  1.15758600e-02,  9.23786610e-02,  4.30153348e-02,\n",
       "        -2.72296350e-02,  1.78653076e-02,  2.65791249e-02,  5.70010394e-02,\n",
       "         1.04300879e-01,  5.20636104e-02,  8.42473842e-03,  5.21024503e-03,\n",
       "        -6.14365237e-03, -5.38077168e-02,  7.10092261e-02,  1.42679987e-02,\n",
       "        -1.88117269e-02, -2.95024272e-02, -8.63009505e-03, -1.04796039e-02,\n",
       "         4.49014343e-02,  5.01187099e-03,  1.01195842e-01, -2.63457149e-02,\n",
       "         5.26679829e-02,  1.01934411e-02,  4.18944806e-02,  1.12960771e-01,\n",
       "         4.45566187e-03, -2.31480021e-02,  9.15847942e-02,  6.05381615e-02,\n",
       "        -3.57244946e-02, -2.42495798e-02,  7.93363899e-03,  1.21713720e-01,\n",
       "         5.41022345e-02, -2.75476146e-02, -1.04860729e-02,  4.05906513e-02,\n",
       "         1.32449353e-02,  3.80662526e-03,  1.03818320e-01,  1.14253640e-01,\n",
       "         6.54197484e-02,  3.22191007e-02, -2.00614110e-02, -8.26627132e-04,\n",
       "         6.02296814e-02,  3.64417257e-03, -6.91243273e-04,  7.74465827e-03,\n",
       "        -2.88866414e-03, -3.31496005e-03,  4.51993458e-02, -1.97683480e-02,\n",
       "        -4.60194834e-02, -3.77844796e-02,  3.23130898e-02,  5.16419997e-03,\n",
       "        -2.61853505e-02, -2.32995916e-02,  5.16988449e-02, -9.80487745e-03,\n",
       "         9.42349609e-04,  3.69182266e-02, -2.64332648e-02,  1.16493620e-01,\n",
       "        -3.85718644e-02,  1.92081071e-02,  9.98017788e-02,  4.84369881e-02,\n",
       "        -8.21908284e-03, -3.43381017e-02,  5.18109575e-02,  7.34902546e-02,\n",
       "         1.52443564e-02, -2.95556020e-02, -3.96431860e-05, -2.89787762e-02,\n",
       "         9.47761461e-02,  2.37700380e-02,  2.01353263e-02, -6.84782118e-03,\n",
       "        -5.33861630e-02, -2.57035773e-02,  2.50568410e-04, -4.18350399e-02,\n",
       "         4.13880199e-02, -3.18707339e-02, -3.61471064e-02,  4.90307622e-03,\n",
       "         5.84484860e-02, -2.02643424e-02,  5.51898498e-03, -4.15671431e-02,\n",
       "        -3.99796143e-02, -5.52665070e-03,  2.29550153e-02, -3.79779711e-02,\n",
       "        -3.95089053e-02, -2.36326065e-02,  3.98002453e-02, -3.10570537e-03,\n",
       "        -1.84777025e-02,  8.22096947e-04,  2.67555621e-02, -4.30127904e-02,\n",
       "         4.37741950e-02,  1.28910076e-02,  2.49419920e-02,  1.38988886e-02,\n",
       "         6.36121929e-02, -4.90884893e-02,  2.02351976e-02, -3.13547216e-02,\n",
       "        -3.80471349e-02,  7.19671473e-02,  1.85610820e-02,  1.84408724e-02,\n",
       "         1.16619371e-01,  2.22792681e-02,  4.37260512e-03,  9.83962640e-02,\n",
       "        -3.36337648e-03, -2.05773357e-02,  4.18588817e-02, -2.01001503e-02,\n",
       "        -3.11472416e-02,  1.57950297e-02,  6.13026544e-02,  3.72797884e-02,\n",
       "         5.93319274e-02,  5.65881766e-02, -3.06778718e-02,  4.33555245e-02,\n",
       "        -3.97161543e-02, -4.85682674e-02,  1.42942816e-02,  2.37006545e-02,\n",
       "        -5.94553724e-03,  2.04055440e-02,  5.77757135e-02, -2.76643839e-02,\n",
       "         1.45521834e-02,  8.33145250e-03,  3.54134329e-02, -1.88920125e-02,\n",
       "         3.98638397e-02,  6.31008670e-02, -1.95943117e-02, -3.15061770e-02,\n",
       "        -4.37399261e-02,  8.57944787e-03,  4.83097928e-03, -2.68601030e-02,\n",
       "         3.55782397e-02,  4.12235558e-02,  6.10118033e-03,  7.15147033e-02,\n",
       "        -8.36629793e-02,  6.53886199e-02, -4.61185351e-02,  2.64854636e-04,\n",
       "         7.32982010e-02,  2.73490008e-02, -1.64105631e-02,  5.97079992e-02,\n",
       "         5.89305870e-02, -3.99671011e-02, -9.89873894e-04, -7.84051325e-03,\n",
       "        -3.59684490e-02,  1.16126738e-01,  8.77198670e-03, -8.07869434e-02,\n",
       "        -1.22013092e-02,  2.20749192e-02,  4.53563519e-02,  7.08202943e-02,\n",
       "         1.89031921e-02,  7.69592868e-03,  1.61180362e-01,  2.60994099e-02,\n",
       "        -1.82832859e-03, -6.08843192e-03,  6.00710809e-02, -4.25208695e-02,\n",
       "         6.85764104e-02, -2.67679002e-02, -2.38200333e-02, -1.57344863e-02,\n",
       "        -4.07580025e-02,  3.34042460e-02,  5.29883467e-02, -3.02885436e-02,\n",
       "        -5.65298833e-02, -8.38467292e-03,  3.63010401e-03, -6.21765619e-04,\n",
       "         6.98571876e-02, -1.12542929e-02, -1.27485711e-02,  1.25399992e-01,\n",
       "        -4.12444957e-03, -2.25761700e-02, -3.29120867e-02, -1.43289622e-02,\n",
       "         1.93609390e-02, -5.27578220e-02,  1.03989402e-02, -9.83915757e-03,\n",
       "         3.90623808e-02,  1.92909781e-02, -1.44755160e-02, -5.47068613e-03,\n",
       "        -6.66460255e-03,  7.17551587e-03, -8.82792100e-03,  7.57245496e-02,\n",
       "         1.48009295e-02,  2.43495265e-03,  7.32520223e-02, -2.72374284e-02,\n",
       "         4.41049784e-02, -8.06930140e-02,  1.31140742e-03, -5.27344681e-02,\n",
       "        -4.99112019e-03,  7.43925804e-03,  7.51455203e-02,  7.77954981e-02,\n",
       "         1.54918572e-02,  3.88827100e-02,  3.95740308e-02, -6.46016076e-02,\n",
       "        -2.49325577e-02, -3.71081270e-02, -3.79331447e-02,  8.32570833e-04,\n",
       "        -3.09248529e-02,  1.09016979e-02, -5.75308055e-02,  2.33336091e-02,\n",
       "         3.79185053e-03,  9.82029364e-02, -4.36451100e-02, -2.13701949e-02,\n",
       "        -1.97871290e-02, -3.04654948e-02, -6.38179667e-03, -2.56088246e-02,\n",
       "         9.20981262e-03,  5.64508513e-02,  7.43210968e-03,  8.91112443e-03,\n",
       "        -2.92466078e-02, -2.05291528e-03, -2.37798020e-02,  2.89010033e-02,\n",
       "         9.10466835e-02,  3.22065428e-02,  5.26510514e-02, -8.53528827e-03,\n",
       "        -6.90320805e-02, -5.80041297e-03, -3.61037105e-02, -3.07418946e-02,\n",
       "        -3.44506428e-02, -3.53542641e-02,  5.58172492e-03,  4.07366902e-02,\n",
       "         2.40364913e-02,  2.05225628e-02, -1.16463425e-02, -1.10640153e-02,\n",
       "        -7.17601031e-02,  2.72796508e-02,  1.33611669e-03, -5.12427557e-03,\n",
       "        -2.46426035e-02,  7.92099815e-03,  7.85088241e-02, -5.83483465e-03,\n",
       "        -8.23713616e-02,  8.89368914e-03,  5.75819910e-02, -3.61591540e-02,\n",
       "        -5.09802550e-02,  3.09503563e-02, -2.20753942e-02,  1.24348421e-02,\n",
       "         5.51394857e-02, -1.61703397e-02, -8.15027952e-03,  7.48290196e-02,\n",
       "         7.75062852e-03, -5.52326366e-02, -2.86368784e-02, -3.43278013e-02,\n",
       "        -2.42312588e-02,  5.52301183e-02,  4.13874090e-02,  1.51339239e-02,\n",
       "        -3.50569226e-02, -2.75948341e-03, -1.66630335e-02,  4.63317409e-02,\n",
       "        -3.89291532e-02,  7.42512494e-02,  1.17558297e-02,  8.98626447e-02,\n",
       "         1.00574851e-01,  3.00769471e-02,  7.13011324e-02,  2.69442960e-03,\n",
       "        -9.13265743e-04, -1.43201277e-02,  1.76216532e-02,  4.85603847e-02,\n",
       "         2.20231479e-04,  5.97026944e-03,  4.41908080e-04,  1.00333802e-01,\n",
       "         4.31936271e-02, -5.62800318e-02,  2.20611431e-02,  4.52769957e-02,\n",
       "         6.18577609e-03,  6.03701919e-03, -4.59153987e-02,  1.47543857e-02,\n",
       "         9.36098918e-02,  3.64285037e-02,  2.95914430e-02, -3.89296468e-03,\n",
       "        -3.34318765e-02,  3.73105891e-02, -4.98969406e-02,  1.06371641e-02,\n",
       "        -7.92752579e-02,  8.09810963e-03,  9.53155011e-03,  4.27080393e-02,\n",
       "         6.36919215e-02, -7.59421438e-02, -4.57227342e-02,  1.01404563e-01,\n",
       "         3.04132346e-02, -2.54139379e-02, -2.72516087e-02,  2.13670079e-04,\n",
       "         2.46486589e-02, -3.26474532e-02,  6.04804978e-02,  5.44102564e-02,\n",
       "        -3.63387428e-02,  5.53860106e-02,  2.28430498e-02, -3.99772413e-02,\n",
       "        -3.01039629e-02,  2.75619905e-02,  1.59304012e-02,  1.01760201e-01,\n",
       "        -2.76043676e-02, -1.48903914e-02, -1.44288251e-02, -2.96806917e-02,\n",
       "         5.73414825e-02,  3.86425131e-03, -3.12885363e-03,  6.28397008e-03,\n",
       "         2.42260378e-02,  1.01737222e-02,  9.34014842e-02,  2.12946814e-02,\n",
       "         5.86459972e-02,  3.21865082e-03, -3.92172411e-02,  1.13206375e-02,\n",
       "         8.31027236e-03, -1.73536353e-02,  5.64281754e-02, -6.51406997e-04,\n",
       "        -2.01688632e-02,  7.36373290e-02,  5.96687645e-02,  6.36565015e-02,\n",
       "        -1.23322755e-02,  3.23469937e-02,  5.49722426e-02, -2.97632702e-02,\n",
       "        -3.76824811e-02, -5.10447565e-03,  1.46995168e-02, -7.15705007e-02,\n",
       "        -9.03777371e-04, -2.07071900e-02,  3.63433361e-02, -4.46234308e-02,\n",
       "         8.06440935e-02,  2.07050685e-02, -5.65695725e-02,  2.84496415e-03,\n",
       "        -1.53787639e-02,  1.19016923e-01, -3.66172865e-02,  4.34267195e-03,\n",
       "         4.89722425e-03,  2.06940584e-02,  2.64576077e-02, -4.99115419e-03,\n",
       "        -5.76796681e-02,  2.87946854e-02, -1.76276118e-02, -3.44157815e-02,\n",
       "         7.17090862e-03, -5.99843487e-02,  3.64089794e-02,  2.59453943e-03],\n",
       "       dtype=float32),\n",
       " array([[ 6.34067804e-02, -3.03729530e-02,  6.13650307e-02, ...,\n",
       "          7.19204843e-02, -6.39783069e-02, -6.90790862e-02],\n",
       "        [-8.47397447e-02, -1.06317289e-01,  8.43217000e-02, ...,\n",
       "         -5.11530275e-03,  8.77771005e-02,  1.55741733e-03],\n",
       "        [-3.95302102e-03, -5.53073771e-02, -5.41413613e-02, ...,\n",
       "          1.41309714e-02,  1.32708073e-01, -8.14434588e-02],\n",
       "        ...,\n",
       "        [-1.17959820e-01,  3.75466682e-02,  1.32621048e-04, ...,\n",
       "         -1.58377290e-02,  3.46448049e-02,  8.97813663e-02],\n",
       "        [-1.32703735e-02, -4.17802036e-02, -8.59013647e-02, ...,\n",
       "          1.16672665e-01,  3.75349671e-02, -1.34048732e-02],\n",
       "        [-6.25547171e-02,  1.16423041e-01, -1.06785998e-01, ...,\n",
       "          1.54553549e-02,  8.38382356e-03, -4.51818400e-04]], dtype=float32),\n",
       " array([0.05051864, 0.01805281, 0.07209811, 0.05321903, 0.09551287,\n",
       "        0.04887329, 0.07967409, 0.06842038, 0.17081751, 0.08007903],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights() # 打印模型中的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x10e50d7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=1) # 返回网络中某一层的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
